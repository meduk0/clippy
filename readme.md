Clippy 🧠🔍

Clippy is a lightweight multimodal semantic search engine that allows users to perform similarity-based searches using either image or text queries. It leverages OpenCLIP for image embeddings and Sentence-Transformers for text embeddings. The app features a simple web interface powered by Flask and returns the most relevant images or text snippets from local datasets.

🚀 Features

🔎 Image-to-Image Search: Upload an image and find visually similar images using CLIP-based embeddings.

📝 Text-to-Text Search: Enter a text query and retrieve the most semantically similar paragraphs.

🖼️ Text-to-Image & Image-to-Text (coming soon!): Cross-modal search functionality planned.

📁 Local Embedding Storage: Uses .npy files for fast cosine similarity lookup.

🧪 Optimized for experimentation, rapid prototyping, and local inference.

🧱 Project Structure

../clippy/
├── clipextract.py              # OpenCLIP model for image embeddings
├── semantic_search.py          # Sentence-Transformers model for text embeddings
├── server.py                   # Backend Flask server
├── static
│   ├── clipfeature             # Image embedding vectors (.npy), generated by clipextract.py
│   ├── images                  # Image dataset for similarity search
│   ├── txt_embeddings          # Text embedding vectors (.npy), generated by semantic_search.py
│   ├── uploaded                # Temporary upload storage for user-submitted images
│   └── wikipedia_paragraphs_train.json  # Raw text dataset
├── templates
│   └── index3.html             # Web frontend template
├── text_db_extract.py          # Extracts and prepares the text dataset

⚙️ Requirements

Python 3.8+

Hugging Face Transformers

OpenCLIP

Flask

NumPy

scikit-learn

Pillow

Install dependencies:

pip install -r requirements.txt

🧠 How It Works

🔹 Image Embeddings

clipextract.py uses OpenCLIP to generate .npy files for each image in the dataset. These vectors are stored in static/clipfeature.

🔹 Text Embeddings

semantic_search.py uses Sentence-Transformers to encode paragraphs from the wikipedia_paragraphs_train.json file and saves them into static/txt_embeddings.

🔹 Web Interface

The Flask app (server.py) serves a simple frontend from index3.html, allowing users to search using an image or text prompt.

🖥️ Running the App

python server.py

Then go to http://localhost:5000 in your browser.

📦 TODO



📄 License

MIT License. See LICENSE for more information.

Let me know if you want badges, deployment instructions (Docker, Hugging Face Spaces), or a section on contributing!
